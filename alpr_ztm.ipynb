{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a156eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5928fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "root = \"/workspace/alpr/\"\n",
    "# dataset_train = alpr.InstanceSegmentationCocoDataset(root = root, images_path=\"images/\", coco_labels_path=\"result_2.json\", transforms=alpr.get_transform(train=True))\n",
    "# dataset_test = alpr.InstanceSegmentationCocoDataset(root = root, images_path=\"images/\", coco_labels_path=\"result_2.json\", transforms=alpr.get_transform(train=True))\n",
    "\n",
    "model = alpr.get_model_instance_segmentation(num_classes, default=True)\n",
    "\n",
    "# engine = alpr.AlprSetupTraining(model, dataset_train, dataset_test, batch_size=2, train_split=0.8)\n",
    "# engine.load_state_dict(path_to_weights=root+\"fasterrcnn_resnet50_fpn_v2.pt\")\n",
    "\n",
    "# num_epochs = 50\n",
    "# engine.train(num_epochs=num_epochs, save_path=root+\"fasterrcnn_resnet50_fpn_v2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b3c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model_instance_segmentation(num_classes, default=True)\n",
    "\n",
    "\n",
    "# iou = engine.eval(show_fr=50, score_threshold=0.7, save_boxes=True)\n",
    "# print(np.mean(iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f750973f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/alpr/frames/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cropper \u001b[39m=\u001b[39m alpr\u001b[39m.\u001b[39;49mAlprSetupPlateCrop(root\u001b[39m=\u001b[39;49mroot, model\u001b[39m=\u001b[39;49mmodel, path_to_imgs\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mframes/\u001b[39;49m\u001b[39m'\u001b[39;49m, idx_start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, idx_end\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m cropper\u001b[39m.\u001b[39mload_state_dict(path_to_weights\u001b[39m=\u001b[39mroot\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfasterrcnn_resnet50_fpn_v2.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m cropper\u001b[39m.\u001b[39mcrop_plates(path_to_save\u001b[39m=\u001b[39mroot\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcroped_plates/2/\u001b[39m\u001b[39m'\u001b[39m, score_threshold\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m)\n",
      "File \u001b[0;32m~/alpr/License-Plate-Detection/alpr.py:299\u001b[0m, in \u001b[0;36mAlprSetupPlateCrop.__init__\u001b[0;34m(self, model, root, path_to_imgs, idx_start, idx_end)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[1;32m    297\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 299\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs_names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(root \u001b[39m+\u001b[39;49m path_to_imgs)))[idx_start:idx_end]\n\u001b[1;32m    300\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mordered_images \u001b[39m=\u001b[39m []\n\u001b[1;32m    301\u001b[0m \u001b[39mfor\u001b[39;00m file_img_path \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspace/alpr/frames/'"
     ]
    }
   ],
   "source": [
    "cropper = alpr.AlprSetupPlateCrop(root=root, model=model, path_to_imgs='frames/', idx_start=0, idx_end=5000)\n",
    "cropper.load_state_dict(path_to_weights=root+\"fasterrcnn_resnet50_fpn_v2.pt\")\n",
    "cropper.crop_plates(path_to_save=root+'croped_plates/2/', score_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0684d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import easyocr\n",
    "# import pytesseract\n",
    "# from cv2 import dnn_superres\n",
    "\n",
    "# reader = easyocr.Reader(['en'])\n",
    "# sr = dnn_superres.DnnSuperResImpl_create()\n",
    "# sr.readModel(root+'EDSR_x3.pb')\n",
    "# sr.setModel(\"edsr\", 3)\n",
    "\n",
    "# # run OCR\n",
    "# for filename in list(sorted(os.listdir(root+\"croped_plates/\")))[:10]:\n",
    "#     img = cv2.imread(root+\"croped_plates/\"+filename)\n",
    "#     upsample_img = sr.upsample(img)\n",
    "#     string = pytesseract.image_to_string(upsample_img)\n",
    "#     # plt.imshow(upsample_img)\n",
    "#     # plt.show()\n",
    "#     print(f\"normal img res -> {img.shape}\")\n",
    "#     print(f\"img upsclaed res -> {upsample_img.shape}\")\n",
    "#     print(f\"detected text -> {string}\")\n",
    "#     # print(img)\n",
    "#     # results = reader.readtext(upsample_img)\n",
    "#     plt.imshow(upsample_img)\n",
    "#     # print(results)\n",
    "#     # print(img.shape)\n",
    "#     # for res in results:\n",
    "#     #     # bbox coordinates of the detected text\n",
    "#     #     xy = res[0]\n",
    "#     #     xy1, xy2, xy3, xy4 = xy[0], xy[1], xy[2], xy[3]\n",
    "#     #     # text results and confidence of detection\n",
    "#     #     det, conf = res[1], res[2]\n",
    "#     #     # show time :)\n",
    "#     #     plt.plot([xy1[0], xy2[0], xy3[0], xy4[0], xy1[0]], [xy1[1], xy2[1], xy3[1], xy4[1], xy1[1]], 'r-')\n",
    "#     #     plt.text(xy1[0], xy1[1], f'{det} [{round(conf, 2)}]')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff035673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145c9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f670a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8d10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340c99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
